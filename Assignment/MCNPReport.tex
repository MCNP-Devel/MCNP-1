%\nonstopmode
\hbadness=100000
\documentclass[a4paper, 12pt]{article}
\usepackage{verbatim,amsmath,graphicx,geometry,textcomp,url,caption}
\geometry{ a4paper, total={170mm,257mm}, left=20mm, top=20mm}

\usepackage[toc, page]{appendix}
\usepackage[dvipsnames]{xcolor}
\definecolor{subr}{rgb}{0.8, 0.33, 0.0}
\definecolor{func}{rgb}{0.76, 0.6, 0.42}

\begin{document}
\begin{center}
MCNP Report										\\
Ocean Wong (Hoi Yeung Wong)						\\
MSc Physics and Technology of Nuclear Reactors	\\
2019-03-09 										\\
\end{center}
\section{Result}
\subsection{Exercise 1 Simple Neutron Source in a Bucket of Water}
\subsubsection{Input file}
Energy cut-off is not applied so that very slow (thermalized) neutrons to interact and let further reactions take place.
\\Therefore the lower bound of the $1^{st}$ bin is 0.
\\The temperature of the cross-section data in databse 42(ENDL92, acquired by Lawrence Livermore National Laboratory) were acrquired at T=300K, as shown in 91-99, and is subsequently adjusted down to 20.4 $C^{o}$ ($2.53 \times 10^{-8}$MeV). Either way, thermal effects should significantly affect that falls into the first 3 energy bins. ($0$-$10^{-9}$MeV, $10^{-9}$-$10^{-8}$MeV,$10^{-8}$-$10^{-7}$MeV respectively).
\\*Insert the pictures of the cross sections of the geometry here, caption with cell number and material number\\

\subsubsection{Output file}
By examining the first 50 particles(using \texttt{PRINT 110}), the source was confirmed to be a point souce 2cm above the centre of the bottom of the tank's internal surface; and the majority of the particles have initial energy $E<4$ MeV as expected when they are distributed according to the Watt spectrum for neutron generated by ${}^{235}U$+n(thermal).
\\*Insert Watt Spectrum .png
\\Note from the Watt spectrum above that there is a small but non-zero probability of getting neutrons of very high energy. This leads to some warning messages when the occassional particle scores above the upper limit of the largest tallying bin.
\\*plot variation of VoV, fom, , as nps increases to 20000\\
\begin{enumerate}
	\item These results are not reliable because the statistical checks (\\*insert number of them not passed\\) are not passed, meaning that some reactions are not sampled enough for us to be confidence about the frequencies of their occurance.
	\\Additionally, some bins in the PDF are empty (seen table 161 of tally 22) suggesting that insufficient number of neutrons is sampled to approximate a continuous distribution.
	\item The total fluences $\Phi$ are simplay calculated by formula $N A \sum_i (\Psi_i)$ 
		\\where each $\Psi_i$ refers to the flux calculated for the i${}^{th}$ energy bin \emph{per history}.
		\\      A = Effective area for surface flux tallying, where the particle passing through still had non-zero weight.
		\\      N = number of histories
		\\Giving \\*create table
	\item The neutron spectra 
	\\*(insert logx histograms using pandas, [dividing by the difference in upper and lower class boundaries so that it gives number density instead?].)
	\\*Copy and modify table above to show their respective means
	\\*The average standard flux $\phi$ i.e. number of neutrons passing through each unit surface area of interest, and the implication (fewer gets their because of the inverse square law)
	\\The hardness of neutron spectrum decreases as follows: hardness at base (Tally 32)$>$long side (Tally 12)$>$short side (Tally 22), because distance of them increases in that order.
	\\More neutrons can penetrate the base at the energy its creation energy without being moderated by the water; therefore the first bin of tally 32is more filled than that of tally 12. 
	\\The ratio of neutron flux in the slow/Cadmium region ($<$0.01 MeV) to neutron flux in the resonance regions ($>$0.01MeV) builds up since the latter gets slowed down/captured by the resonance peaks much faster than the rate of consumption of the former, as they travel through the material.
\end{enumerate}
Note that the $1^{st}$ bin ($0$ to $1\times 10^{-9}$ MeV) is below the thermal energy of room temperature; neutrons of these energies are strongly affected by the free gas thermal treatment of the interaction cross sections; additionally due to the large cross section in the thermal region which increases as the neutron slows, very few neutrons of these energies can travel far enough to be counted by these surface flux tallies. Therefore this bin always have the largest relative errors among all bins.

To ensure that no bins have relative error larger than 0.10 to ensure that the results are reasonable, enough histories must be ran to allow this energy bin in all 3 tallies to be filled sufficiently, in addition to passing all 10 statistical checks.

The tally probability distributions (histograms shown in table 161's) all show reasonably Gaussian distributions (and the cumulative probability distributions all show reasonably sigmoidal distributions) without the majority of the counts falling into a particular bin; therefore there is no inherent reason for using a finer spacing; but for the purpose of visualizing the spectrum with a higher resolution, a finer group structure with trifolded bin density (still logarithmically spaced, 3 bins per decade) was used.
\\Even when the spacing of energy groups is trisected in this manner, the $1^{st}$ bin ($0$ to $1\times 10^{-9}$ MeV) is still the bin that receives the least counts. In a real problem this would've been merged with the $2^{nd}$ bin to form a single, larger bin to tally up all the completely thermalized neutrons, increasing its count so that it converges to a precise enough value in a shorter CPU time; but according to the constraint of the problem, there must be one bin with ${10^{-9}}$ MeV as the upper limit. Therefore the only option left is to increase the number of histories such that the results of this bin converges.
\\Even after running 500000 histories, the relative error for this bin remains high ($0.2599$, $0.4236$, $0.3681$, for tally 12, 22, and 32, respectively) despite the fact that all other statistical checks were passed and the fom has alreay converged to a stable asymptotic limit.

The number of histories to run is chosen as \\*, empirically shown to give a result that converges (passes all 10 statistical checks) in a reasonable CPU time of * minutes.

\subsection{Exercise 3: Criticality}
\subsubsection{Input file}
\paragraph{Geometry definition}
It is easier geometry to define the geometry if a sphere was used to define the graveyard (void) outside; but a cuboidal geometry was chosen instead to allow the surface flux detectors (F2) to tally particles passing through lateral surfaces separately from particles passing through horizontal surfaces.
\\All components except the concrete floor had the same neutron importance. Neutron importance in concrete started off at 1 but was subsequently reduced to 0.1 such that the simulation runs faster by ignoring particles that enter the concrete, since they will otherwise undergo a lot of collision (each requiring a lot of CPU time) to slow down, without causing multiplication.
\\If the mean free path to absorption $\lambda_{\text{abs}}$ is known, the dimension of the concrete floor can be chosen to extend from the stainless steel tank by $N\lambda_{\text{abs}}$ where N is some arbitrary threshold factor (e.g. 3).
\\However only the mean free path to collision for neutron is found on a Cell particle activity table (using \texttt{PRINT 126}). Since concrete is only a weakly neutron-absorbing medium, this cannot be used as the proxy for $\lambda_{\text{abs}}$.
\\Instead the number of neutrons travelling from the concrete to the void region (where neutron importance = 0) was compared to the number of neutrons entering the concrete. The simulation is considered accurate when the ratio of these two numbers is less than 1\%, i.e. $<$ 1\% of the neutrons entering the concrete were "killed" (by entering the void) before they were absorbed/reflected back towards the tank. The dimension of the concrete block was increased until this ratio is low enough.
\\It was found the ratio of \underline{neutrons entering the concrete} vs. \underline{travelling from the concrete into void} reached \\* \% when the concrete floor block extends from the tank by \\*cm more in each direction, i.e. when the floor is \\*cm larger than the tank in the +x, -x, +y, and -y directions; and is \\*cm deep in the z-direction.

\paragraph{Source definition}
Using \texttt{SDEF}'s default option, a "generic Watt spectrum"(\\* Quote MCNP manaul) of neutron was created.
\\The neutron source was defined using the position = distribution 1 (\texttt{POS=D1}) option in the \texttt{SDEF} card, where distribution 1 \texttt{SI1 L ...} refers to the centres of all of the cylinders; so that the \texttt{SDEF} card as a whole gives a homogeneous isotropic probability distribution of generating a neutron in all of the Uranium cylinders.
\\This allowed for very fast convergence of the results, where the $\text{k}_{\text{eff}}$ settled down in less than 10 generations; but to be safe 100 generations were skipped (because it isn't computationally expensive to do so).
\\There is an alternative method of generating such; (which is similar to using a cookie cutter); but that will cause a lot of particles to be rejected.
\subsubsection{Questions}
\begin{itemize}
	\item Examine and report upon the estimate of $k_{\text{eff}}$ with cycle number given in the output.
	\item Are you confident in the final reported result and its uncertainty? Justify your answer.
	\begin{itemize}
		\item make sure that the 10 statistical checks pass on all cells
	\end{itemize}
	\item In addition to Monte Carlo stochastic uncertainties what other uncertainties may need 
	to be considered in a criticality safety assessment?
\end{itemize}

\end{document}